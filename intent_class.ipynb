{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install -q pandas torch scikit-learn"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EKKNHE2EcS48",
        "outputId": "b32ddc06-3066-4d8a-8049-231983d1f7df"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m27.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m23.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m102.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Setup and Imports"
      ],
      "metadata": {
        "id": "YJVXwRETcddd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from collections import Counter\n",
        "import re\n",
        "import pickle\n",
        "import csv\n",
        "\n",
        "print(\"Libraries imported successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Tu4QyRWcaZ5",
        "outputId": "3a8a49ed-cb7b-4235-940e-14abb9f64a81"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Libraries imported successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Load and Preprocess Data"
      ],
      "metadata": {
        "id": "SWH4rqA6cq1i"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Load your dataset from the uploaded 'intent.csv' file.\n",
        "try:\n",
        "    df = pd.read_csv('intent.csv', skiprows=1, header=None, names=['raw_data'])\n",
        "    df[['text', 'intent']] = df['raw_data'].str.split(',', n=1, expand=True)\n",
        "    df['text'] = df['text'].str.strip('\" ')\n",
        "    df['intent'] = df['intent'].str.strip('\" ')\n",
        "    print(\"Successfully loaded and parsed 'intent.csv'.\")\n",
        "\n",
        "except FileNotFoundError:\n",
        "    print(\"Error: 'intent.csv' not found.\")\n",
        "    print(\"Please make sure you have uploaded the file to your Colab session.\")\n",
        "    data = {'text': ['tell me a joke', 'what is the weather like', 'play some music',\n",
        "                     'how are you', 'what is the temperature', 'I want to hear a song'],\n",
        "            'intent': ['joke', 'weather', 'music', 'greeting', 'weather', 'music']}\n",
        "    df = pd.DataFrame(data)\n",
        "    print(\"\\nUsing a dummy dataframe for demonstration.\")\n",
        "\n",
        "# --- Inspect the class distribution to see the problem ---\n",
        "print(\"\\n--- Examining Intent Counts ---\")\n",
        "print(\"This shows how many examples exist for each intent category:\")\n",
        "print(df['intent'].value_counts())\n",
        "print(\"---------------------------------\")\n",
        "\n",
        "\n",
        "# Basic text cleaning function\n",
        "def clean_text(text):\n",
        "    if not isinstance(text, str):\n",
        "        return \"\"\n",
        "    text = re.sub(r'[^a-zA-Z\\s]', '', text, re.I|re.A)\n",
        "    text = text.lower()\n",
        "    text = text.strip()\n",
        "    return text\n",
        "\n",
        "df['text'] = df['text'].apply(clean_text)\n",
        "\n",
        "# Encode the labels\n",
        "label_encoder = LabelEncoder()\n",
        "df['intent_encoded'] = label_encoder.fit_transform(df['intent'])\n",
        "print(\"\\nLabels encoded:\")\n",
        "print(dict(zip(label_encoder.classes_, label_encoder.transform(label_encoder.classes_))))\n",
        "\n",
        "\n",
        "# Split data into training and validation sets\n",
        "# --- CORRECTED LINE: Removed 'stratify' parameter ---\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    df['text'],\n",
        "    df['intent_encoded'],\n",
        "    test_size=0.2,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "print(f\"\\nTraining set size: {len(X_train)}\")\n",
        "print(f\"Validation set size: {len(X_val)}\")\n",
        "\n",
        "print(\"\\nFinal processed DataFrame head:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K6egg3fhcnW2",
        "outputId": "d5eaf33f-74c6-47ec-86e1-f92612ad6580"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Successfully loaded and parsed 'intent.csv'.\n",
            "\n",
            "--- Examining Intent Counts ---\n",
            "This shows how many examples exist for each intent category:\n",
            "intent\n",
            "product info      20\n",
            "get directions    20\n",
            "repeat            20\n",
            "Name: count, dtype: int64\n",
            "---------------------------------\n",
            "\n",
            "Labels encoded:\n",
            "{'get directions': np.int64(0), 'product info': np.int64(1), 'repeat': np.int64(2)}\n",
            "\n",
            "Training set size: 48\n",
            "Validation set size: 12\n",
            "\n",
            "Final processed DataFrame head:\n",
            "                                            raw_data  \\\n",
            "0  \"What's the price of the Model Z headphones?\",...   \n",
            "1  \"Can you tell me the battery life of the X200 ...   \n",
            "2  \"Do you have information on the dimensions of ...   \n",
            "3  \"What's the availability of the Galaxy S21 in ...   \n",
            "4  \"Give me specs for the TurboMax laptop.\",\"prod...   \n",
            "\n",
            "                                                text        intent  \\\n",
            "0          whats the price of the model z headphones  product info   \n",
            "1  can you tell me the battery life of the x smar...  product info   \n",
            "2  do you have information on the dimensions of t...  product info   \n",
            "3     whats the availability of the galaxy s in blue  product info   \n",
            "4              give me specs for the turbomax laptop  product info   \n",
            "\n",
            "   intent_encoded  \n",
            "0               1  \n",
            "1               1  \n",
            "2               1  \n",
            "3               1  \n",
            "4               1  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Build Vocabulary"
      ],
      "metadata": {
        "id": "wv_VJTHzcyMo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Build vocabulary from the training data\n",
        "counter = Counter()\n",
        "for text in X_train:\n",
        "    counter.update(text.split())\n",
        "\n",
        "# Create a word-to-index dictionary\n",
        "# Start with special tokens\n",
        "word_to_idx = {'<pad>': 0, '<unk>': 1}\n",
        "# Start indexing from 2, since 0 and 1 are taken\n",
        "idx = 2\n",
        "for word, count in counter.most_common():\n",
        "    word_to_idx[word] = idx\n",
        "    idx += 1\n",
        "\n",
        "vocab_size = len(word_to_idx)\n",
        "print(f\"Vocabulary size: {vocab_size}\")\n",
        "\n",
        "# Example: Get the index of a word\n",
        "print(f\"Index of 'the': {word_to_idx.get('the', 1)}\") # Use .get() to handle unknown words\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-m5dhisvc5QL",
        "outputId": "944f0046-6742-4e54-8a23-6738ed2fe05c"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 187\n",
            "Index of 'the': 2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create PyTorch Dataset"
      ],
      "metadata": {
        "id": "U8AntowWdiQp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntentDataset(Dataset):\n",
        "    def __init__(self, texts, labels, vocabulary, max_len=20):\n",
        "        self.texts = texts\n",
        "        self.labels = labels\n",
        "        self.vocabulary = vocabulary\n",
        "        self.max_len = max_len\n",
        "        self.unk_token_idx = vocabulary['<unk>']\n",
        "        self.pad_token_idx = vocabulary['<pad>']\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        text = self.texts.iloc[idx]\n",
        "        label = self.labels.iloc[idx]\n",
        "\n",
        "        # Tokenize and numericalize using the dictionary\n",
        "        tokens = text.split()\n",
        "        # Use .get() to default to the <unk> token index if a word is not in the vocabulary\n",
        "        token_indices = [self.vocabulary.get(token, self.unk_token_idx) for token in tokens]\n",
        "\n",
        "        # Pad or truncate the sequence\n",
        "        if len(token_indices) < self.max_len:\n",
        "            # Pad with the index of <pad> token\n",
        "            token_indices.extend([self.pad_token_idx] * (self.max_len - len(token_indices)))\n",
        "        else:\n",
        "            token_indices = token_indices[:self.max_len]\n",
        "\n",
        "        return torch.tensor(token_indices, dtype=torch.long), torch.tensor(label, dtype=torch.long)\n",
        "\n",
        "# Define max sequence length\n",
        "MAX_LEN = 25\n",
        "\n",
        "# Create dataset instances\n",
        "train_dataset = IntentDataset(X_train, y_train, word_to_idx, MAX_LEN)\n",
        "val_dataset = IntentDataset(X_val, y_val, word_to_idx, MAX_LEN)\n",
        "\n",
        "# Example of one item from the dataset\n",
        "print(\"Example item from the dataset:\")\n",
        "print(train_dataset[0])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyYjG5Q5dhkj",
        "outputId": "f4373823-2ee8-41e2-9869-833875e87fff"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Example item from the dataset:\n",
            "(tensor([43,  8, 10,  6, 23,  6, 44, 45, 46,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
            "         0,  0,  0,  0,  0,  0,  0]), tensor(0))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define the Lightweight Model"
      ],
      "metadata": {
        "id": "E5G6ESfXdnSc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class IntentClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, num_class):\n",
        "        super(IntentClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        # Using a simple averaging of embeddings instead of a complex RNN/LSTM\n",
        "        # This is a form of a \"Continuous Bag-of-Words\" (CBOW) model.\n",
        "        self.fc = nn.Linear(embed_dim, num_class)\n",
        "\n",
        "    def forward(self, text):\n",
        "        # text shape: (batch_size, seq_len)\n",
        "        embedded = self.embedding(text)\n",
        "        # embedded shape: (batch_size, seq_len, embed_dim)\n",
        "\n",
        "        # Average the embeddings across the sequence length dimension\n",
        "        # The mean operation needs to ignore padding. We can do this by creating a mask.\n",
        "        mask = (text != 0).float().unsqueeze(2)\n",
        "        embedded = embedded * mask\n",
        "        summed = torch.sum(embedded, 1)\n",
        "        non_pad_count = mask.sum(1)\n",
        "        mean_embedded = summed / (non_pad_count + 1e-9) # Add epsilon to avoid division by zero\n",
        "        # mean_embedded shape: (batch_size, embed_dim)\n",
        "\n",
        "        return self.fc(mean_embedded)\n",
        "\n",
        "# Hyperparameters\n",
        "EMBED_DIM = 32 # Keep this small for a lightweight model\n",
        "NUM_CLASSES = len(label_encoder.classes_)\n",
        "BATCH_SIZE = 8\n",
        "\n",
        "# Instantiate the model\n",
        "model = IntentClassifier(vocab_size, EMBED_DIM, NUM_CLASSES)\n",
        "print(\"Model architecture:\")\n",
        "print(model)\n",
        "\n",
        "# Dataloaders\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jDMbwB2zdn0o",
        "outputId": "0f96a92c-841b-418d-fd58-148249d58913"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model architecture:\n",
            "IntentClassifier(\n",
            "  (embedding): Embedding(187, 32, padding_idx=0)\n",
            "  (fc): Linear(in_features=32, out_features=3, bias=True)\n",
            ")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train the Model"
      ],
      "metadata": {
        "id": "p7cpwXQqdrXY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Training parameters\n",
        "LEARNING_RATE = 0.005\n",
        "EPOCHS = 50 # Increase if needed, but watch for overfitting\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
        "\n",
        "# Training loop\n",
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    total_acc = 0\n",
        "\n",
        "    for texts, labels in train_dataloader:\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(texts)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        # Calculate accuracy\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total_acc += (predicted == labels).sum().item()\n",
        "\n",
        "    # Print training stats\n",
        "    avg_loss = total_loss / len(train_dataloader)\n",
        "    avg_acc = total_acc / len(train_dataset)\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS}, Train Loss: {avg_loss:.4f}, Train Acc: {avg_acc:.4f}')\n",
        "\n",
        "    # Validation loop\n",
        "    model.eval()\n",
        "    val_loss = 0\n",
        "    val_acc = 0\n",
        "    with torch.no_grad():\n",
        "        for texts, labels in val_dataloader:\n",
        "            outputs = model(texts)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            val_acc += (predicted == labels).sum().item()\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_dataloader)\n",
        "    avg_val_acc = val_acc / len(val_dataset)\n",
        "    print(f'Epoch {epoch+1}/{EPOCHS}, Val Loss: {avg_val_loss:.4f},   Val Acc: {avg_val_acc:.4f}\\n')\n",
        "\n",
        "print(\"Training complete!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDYOkzj-dtiI",
        "outputId": "89b1a19d-706e-4d76-eba2-9c3c66f133a6"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/50, Train Loss: 1.1527, Train Acc: 0.2500\n",
            "Epoch 1/50, Val Loss: 1.1137,   Val Acc: 0.3333\n",
            "\n",
            "Epoch 2/50, Train Loss: 1.0584, Train Acc: 0.3958\n",
            "Epoch 2/50, Val Loss: 1.0367,   Val Acc: 0.5000\n",
            "\n",
            "Epoch 3/50, Train Loss: 0.9776, Train Acc: 0.5417\n",
            "Epoch 3/50, Val Loss: 0.9643,   Val Acc: 0.6667\n",
            "\n",
            "Epoch 4/50, Train Loss: 0.8985, Train Acc: 0.7292\n",
            "Epoch 4/50, Val Loss: 0.9050,   Val Acc: 0.5833\n",
            "\n",
            "Epoch 5/50, Train Loss: 0.8280, Train Acc: 0.8125\n",
            "Epoch 5/50, Val Loss: 0.8402,   Val Acc: 0.6667\n",
            "\n",
            "Epoch 6/50, Train Loss: 0.7517, Train Acc: 0.8542\n",
            "Epoch 6/50, Val Loss: 0.7737,   Val Acc: 0.6667\n",
            "\n",
            "Epoch 7/50, Train Loss: 0.6781, Train Acc: 0.8958\n",
            "Epoch 7/50, Val Loss: 0.7146,   Val Acc: 0.6667\n",
            "\n",
            "Epoch 8/50, Train Loss: 0.6039, Train Acc: 0.9167\n",
            "Epoch 8/50, Val Loss: 0.6545,   Val Acc: 0.6667\n",
            "\n",
            "Epoch 9/50, Train Loss: 0.5310, Train Acc: 0.9583\n",
            "Epoch 9/50, Val Loss: 0.5929,   Val Acc: 0.7500\n",
            "\n",
            "Epoch 10/50, Train Loss: 0.4627, Train Acc: 0.9792\n",
            "Epoch 10/50, Val Loss: 0.5369,   Val Acc: 0.7500\n",
            "\n",
            "Epoch 11/50, Train Loss: 0.3989, Train Acc: 1.0000\n",
            "Epoch 11/50, Val Loss: 0.4835,   Val Acc: 0.8333\n",
            "\n",
            "Epoch 12/50, Train Loss: 0.3408, Train Acc: 1.0000\n",
            "Epoch 12/50, Val Loss: 0.4376,   Val Acc: 0.8333\n",
            "\n",
            "Epoch 13/50, Train Loss: 0.2901, Train Acc: 1.0000\n",
            "Epoch 13/50, Val Loss: 0.3981,   Val Acc: 0.8333\n",
            "\n",
            "Epoch 14/50, Train Loss: 0.2457, Train Acc: 1.0000\n",
            "Epoch 14/50, Val Loss: 0.3622,   Val Acc: 0.8333\n",
            "\n",
            "Epoch 15/50, Train Loss: 0.2080, Train Acc: 1.0000\n",
            "Epoch 15/50, Val Loss: 0.3318,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 16/50, Train Loss: 0.1769, Train Acc: 1.0000\n",
            "Epoch 16/50, Val Loss: 0.3068,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 17/50, Train Loss: 0.1511, Train Acc: 1.0000\n",
            "Epoch 17/50, Val Loss: 0.2841,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 18/50, Train Loss: 0.1285, Train Acc: 1.0000\n",
            "Epoch 18/50, Val Loss: 0.2655,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 19/50, Train Loss: 0.1109, Train Acc: 1.0000\n",
            "Epoch 19/50, Val Loss: 0.2483,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 20/50, Train Loss: 0.0961, Train Acc: 1.0000\n",
            "Epoch 20/50, Val Loss: 0.2341,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 21/50, Train Loss: 0.0839, Train Acc: 1.0000\n",
            "Epoch 21/50, Val Loss: 0.2219,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 22/50, Train Loss: 0.0732, Train Acc: 1.0000\n",
            "Epoch 22/50, Val Loss: 0.2111,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 23/50, Train Loss: 0.0655, Train Acc: 1.0000\n",
            "Epoch 23/50, Val Loss: 0.2017,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 24/50, Train Loss: 0.0578, Train Acc: 1.0000\n",
            "Epoch 24/50, Val Loss: 0.1935,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 25/50, Train Loss: 0.0516, Train Acc: 1.0000\n",
            "Epoch 25/50, Val Loss: 0.1860,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 26/50, Train Loss: 0.0464, Train Acc: 1.0000\n",
            "Epoch 26/50, Val Loss: 0.1795,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 27/50, Train Loss: 0.0418, Train Acc: 1.0000\n",
            "Epoch 27/50, Val Loss: 0.1735,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 28/50, Train Loss: 0.0379, Train Acc: 1.0000\n",
            "Epoch 28/50, Val Loss: 0.1682,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 29/50, Train Loss: 0.0347, Train Acc: 1.0000\n",
            "Epoch 29/50, Val Loss: 0.1631,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 30/50, Train Loss: 0.0321, Train Acc: 1.0000\n",
            "Epoch 30/50, Val Loss: 0.1586,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 31/50, Train Loss: 0.0293, Train Acc: 1.0000\n",
            "Epoch 31/50, Val Loss: 0.1545,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 32/50, Train Loss: 0.0271, Train Acc: 1.0000\n",
            "Epoch 32/50, Val Loss: 0.1508,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 33/50, Train Loss: 0.0251, Train Acc: 1.0000\n",
            "Epoch 33/50, Val Loss: 0.1470,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 34/50, Train Loss: 0.0233, Train Acc: 1.0000\n",
            "Epoch 34/50, Val Loss: 0.1436,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 35/50, Train Loss: 0.0217, Train Acc: 1.0000\n",
            "Epoch 35/50, Val Loss: 0.1402,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 36/50, Train Loss: 0.0203, Train Acc: 1.0000\n",
            "Epoch 36/50, Val Loss: 0.1373,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 37/50, Train Loss: 0.0190, Train Acc: 1.0000\n",
            "Epoch 37/50, Val Loss: 0.1344,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 38/50, Train Loss: 0.0179, Train Acc: 1.0000\n",
            "Epoch 38/50, Val Loss: 0.1317,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 39/50, Train Loss: 0.0168, Train Acc: 1.0000\n",
            "Epoch 39/50, Val Loss: 0.1293,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 40/50, Train Loss: 0.0158, Train Acc: 1.0000\n",
            "Epoch 40/50, Val Loss: 0.1273,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 41/50, Train Loss: 0.0150, Train Acc: 1.0000\n",
            "Epoch 41/50, Val Loss: 0.1251,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 42/50, Train Loss: 0.0141, Train Acc: 1.0000\n",
            "Epoch 42/50, Val Loss: 0.1233,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 43/50, Train Loss: 0.0134, Train Acc: 1.0000\n",
            "Epoch 43/50, Val Loss: 0.1213,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 44/50, Train Loss: 0.0127, Train Acc: 1.0000\n",
            "Epoch 44/50, Val Loss: 0.1194,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 45/50, Train Loss: 0.0121, Train Acc: 1.0000\n",
            "Epoch 45/50, Val Loss: 0.1176,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 46/50, Train Loss: 0.0115, Train Acc: 1.0000\n",
            "Epoch 46/50, Val Loss: 0.1160,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 47/50, Train Loss: 0.0110, Train Acc: 1.0000\n",
            "Epoch 47/50, Val Loss: 0.1144,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 48/50, Train Loss: 0.0104, Train Acc: 1.0000\n",
            "Epoch 48/50, Val Loss: 0.1130,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 49/50, Train Loss: 0.0100, Train Acc: 1.0000\n",
            "Epoch 49/50, Val Loss: 0.1115,   Val Acc: 1.0000\n",
            "\n",
            "Epoch 50/50, Train Loss: 0.0096, Train Acc: 1.0000\n",
            "Epoch 50/50, Val Loss: 0.1102,   Val Acc: 1.0000\n",
            "\n",
            "Training complete!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Save the Model for Mobile"
      ],
      "metadata": {
        "id": "OpdskN_JdyIu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ensure the model is in evaluation mode\n",
        "model.eval()\n",
        "\n",
        "# Create an example input tensor. This is needed for tracing.\n",
        "# The shape should match a single input to the model.\n",
        "example_input = torch.randint(0, vocab_size, (1, MAX_LEN), dtype=torch.long)\n",
        "\n",
        "# Trace the model\n",
        "traced_script_module = torch.jit.trace(model, example_input)\n",
        "\n",
        "# Save the traced model\n",
        "# This .ptl file is the one you will use in your Android app with PyTorch Mobile.\n",
        "model_filename_mobile = \"intent_model_mobile.ptl\"\n",
        "traced_script_module._save_for_lite_interpreter(model_filename_mobile)\n",
        "\n",
        "print(f\"Model saved for mobile deployment as '{model_filename_mobile}'\")\n",
        "\n",
        "# You can also save the regular state dict for later use in Python\n",
        "model_filename_pytorch = \"intent_model_pytorch.pth\"\n",
        "torch.save(model.state_dict(), model_filename_pytorch)\n",
        "print(f\"Standard PyTorch model state_dict saved as '{model_filename_pytorch}'\")\n",
        "\n",
        "# Also save the vocabulary and label encoder, you'll need them for inference\n",
        "import pickle\n",
        "\n",
        "with open('vocabulary.pkl', 'wb') as f:\n",
        "    pickle.dump(word_to_idx, f)\n",
        "\n",
        "with open('label_encoder.pkl', 'wb') as f:\n",
        "    pickle.dump(label_encoder, f)\n",
        "\n",
        "print(\"Vocabulary and Label Encoder also saved.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FFDTd_STdzlp",
        "outputId": "da36bd06-20b2-4242-947e-85be5e627747"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved for mobile deployment as 'intent_model_mobile.ptl'\n",
            "Standard PyTorch model state_dict saved as 'intent_model_pytorch.pth'\n",
            "Vocabulary and Label Encoder also saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Evaluation, Inference, and Model Stats"
      ],
      "metadata": {
        "id": "YtLIOyjJOGgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# --- 1. Load the necessary artifacts ---\n",
        "# You would typically do this in your application\n",
        "# For this notebook, we can reuse the objects from previous cells,\n",
        "# but we'll load them to demonstrate the full process.\n",
        "\n",
        "# Load the vocabulary and label encoder\n",
        "with open('vocabulary.pkl', 'rb') as f:\n",
        "    word_to_idx = pickle.load(f)\n",
        "\n",
        "with open('label_encoder.pkl', 'rb') as f:\n",
        "    label_encoder = pickle.load(f)\n",
        "\n",
        "# Re-instantiate the model structure\n",
        "# Make sure the parameters match the ones used for training\n",
        "vocab_size = len(word_to_idx)\n",
        "EMBED_DIM = 32 # Should be the same as in Cell 5\n",
        "NUM_CLASSES = len(label_encoder.classes_) # Should be the same as in Cell 5\n",
        "model_eval = IntentClassifier(vocab_size, EMBED_DIM, NUM_CLASSES)\n",
        "\n",
        "# Load the trained weights\n",
        "# For evaluation in Python, it's easier to use the .pth file\n",
        "model_eval.load_state_dict(torch.load(\"intent_model_pytorch.pth\"))\n",
        "model_eval.eval() # Set the model to evaluation mode\n",
        "\n",
        "print(\"Model, vocabulary, and label encoder loaded successfully.\\n\")\n",
        "\n",
        "\n",
        "# --- 2. Model Information ---\n",
        "# Calculate the total number of parameters\n",
        "total_params = sum(p.numel() for p in model_eval.parameters() if p.requires_grad)\n",
        "print(f\"Total trainable parameters: {total_params:,}\")\n",
        "\n",
        "# Get the size of the saved mobile-optimized model file\n",
        "try:\n",
        "    model_size_bytes = os.path.getsize(\"intent_model_mobile.ptl\")\n",
        "    model_size_kb = model_size_bytes / 1024\n",
        "    print(f\"Size of the mobile model file ('intent_model_mobile.ptl'): {model_size_kb:.2f} KB\")\n",
        "except FileNotFoundError:\n",
        "    print(\"Mobile model file not found.\")\n",
        "\n",
        "print(\"-\" * 30)\n",
        "\n",
        "# --- 3. Prediction Function and Inference Time ---\n",
        "MAX_LEN = 25 # Should be the same as in Cell 4\n",
        "unk_token_idx = word_to_idx['<unk>']\n",
        "pad_token_idx = word_to_idx['<pad>']\n",
        "\n",
        "def predict_intent(sentence):\n",
        "    # Preprocess the sentence\n",
        "    cleaned_sentence = clean_text(sentence)\n",
        "    tokens = cleaned_sentence.split()\n",
        "\n",
        "    # Numericalize\n",
        "    token_indices = [word_to_idx.get(token, unk_token_idx) for token in tokens]\n",
        "\n",
        "    # Pad/Truncate\n",
        "    if len(token_indices) < MAX_LEN:\n",
        "        token_indices.extend([pad_token_idx] * (MAX_LEN - len(token_indices)))\n",
        "    else:\n",
        "        token_indices = token_indices[:MAX_LEN]\n",
        "\n",
        "    # Convert to tensor\n",
        "    text_tensor = torch.tensor(token_indices, dtype=torch.long).unsqueeze(0) # Add batch dimension\n",
        "\n",
        "    # Get prediction\n",
        "    with torch.no_grad():\n",
        "        output = model_eval(text_tensor)\n",
        "        _, predicted_idx = torch.max(output.data, 1)\n",
        "\n",
        "    # Decode the prediction\n",
        "    predicted_intent = label_encoder.inverse_transform(predicted_idx.numpy())[0]\n",
        "    return predicted_intent\n",
        "\n",
        "# --- 4. Evaluate on Test Sentences ---\n",
        "test_sentences = [\n",
        "    \"How big is this tomato sauce?\",\n",
        "    \"Sorry repeat that?\",\n",
        "    \"Where can I buy meat?\",\n",
        "    \"Show me nutriments infos of this cereal box.\"\n",
        "]\n",
        "\n",
        "print(\"\\nRunning predictions on test sentences:\")\n",
        "for sentence in test_sentences:\n",
        "    prediction = predict_intent(sentence)\n",
        "    print(f\"Sentence: '{sentence}'\")\n",
        "    print(f\"--> Predicted Intent: '{prediction}'\\n\")\n",
        "\n",
        "# --- 5. Measure Inference Time ---\n",
        "# Let's measure the time for one prediction.\n",
        "# We run it once to warm up, then time it.\n",
        "_ = predict_intent(\"this is a warm-up sentence\")\n",
        "\n",
        "start_time = time.perf_counter()\n",
        "_ = predict_intent(\"what is the weather like today\")\n",
        "end_time = time.perf_counter()\n",
        "\n",
        "inference_time_ms = (end_time - start_time) * 1000\n",
        "print(\"-\" * 30)\n",
        "print(f\"Single sentence inference time: {inference_time_ms:.4f} ms\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KxLSMBnOKgk",
        "outputId": "80c26ca0-3b85-4d47-cdf6-8a62624458c5"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model, vocabulary, and label encoder loaded successfully.\n",
            "\n",
            "Total trainable parameters: 6,083\n",
            "Size of the mobile model file ('intent_model_mobile.ptl'): 33.59 KB\n",
            "------------------------------\n",
            "\n",
            "Running predictions on test sentences:\n",
            "Sentence: 'How big is this tomato sauce?'\n",
            "--> Predicted Intent: 'get directions'\n",
            "\n",
            "Sentence: 'Sorry repeat that?'\n",
            "--> Predicted Intent: 'repeat'\n",
            "\n",
            "Sentence: 'Where can I buy meat?'\n",
            "--> Predicted Intent: 'get directions'\n",
            "\n",
            "Sentence: 'Show me nutriments infos of this cereal box.'\n",
            "--> Predicted Intent: 'product info'\n",
            "\n",
            "------------------------------\n",
            "Single sentence inference time: 0.6554 ms\n"
          ]
        }
      ]
    }
  ]
}